{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf6862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.8/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.8/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.8/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "c8043312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "3ce67c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = open('names.txt','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "0053f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "print(names_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "8554a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "char_to_int['.'] = 0\n",
    "int_to_char[0] = '.'\n",
    "\n",
    "for char_num in range(ord('a'),ord('z')+1):\n",
    "    integer_representation = char_num-ord('a')+1\n",
    "    char_to_int[chr(char_num)] = integer_representation\n",
    "    int_to_char[integer_representation] = chr(char_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "cd193dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "0853e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "embed_size = 4\n",
    "\n",
    "state_size = 10\n",
    "\n",
    "hidden_size = 25\n",
    "\n",
    "vocab_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "84d731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "char_vector_size = 2\n",
    "input_contexts , input_labels = [[] for _ in range(5)], [[] for _ in range(5)]\n",
    "\n",
    "for name in names_list:\n",
    "    log_padded_length = math.ceil(math.log(len(name))/math.log(2))\n",
    "    padded_length = int(2**log_padded_length)\n",
    "    context = [char_to_int[char] for char in name]  + [0] + [vocab_size-1]*(padded_length-len(name)) \n",
    "    input_contexts[log_padded_length].append(context)\n",
    "#   instead of using labels, we can compare the result to the character vectors to find a likely match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "e63c25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = input_contexts[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "40819a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "all_char_embeds = torch.randn((vocab_size,embed_size))\n",
    "\n",
    "all_char_embeds[vocab_size-1] = 10**10\n",
    "\n",
    "w_eh = torch.randn((embed_size, hidden_size)) * 0.5\n",
    "\n",
    "w_sh = torch.randn((state_size, hidden_size)) * 0.5\n",
    "w_so = torch.randn((state_size, embed_size)) *0.5\n",
    "\n",
    "w_hs = torch.randn((hidden_size, state_size)) *0.5\n",
    "\n",
    "b_h = torch.zeros((hidden_size,))\n",
    "b_s = torch.zeros((state_size,))\n",
    "b_o = torch.zeros((embed_size,))\n",
    "\n",
    "init_state = torch.randn((state_size,)) * 0.5\n",
    "\n",
    "network_params = [init_state,w_eh,w_sh,w_so,w_hs,b_h,b_s,b_o,all_char_embeds]\n",
    "\n",
    "for p in network_params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "68feafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_and_embed(states , embeds, hiddens, outputs, idx):\n",
    "    hiddens[idx] = 2*torch.sigmoid((states[idx] @ w_sh) + (embeds[idx] @ w_eh) + b_h) -1\n",
    "    states[idx+1] = hiddens[idx] @ w_hs + b_s\n",
    "    outputs[idx] = states[idx] @ w_so + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "0ed9af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in range(len(input_contexts)):\n",
    "    input_contexts[i] = torch.tensor(input_contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "fef2cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 of 50000:  tensor(0.0100, grad_fn=<DivBackward0>)\n",
      "1000 of 50000:  tensor(0.0102, grad_fn=<DivBackward0>)\n",
      "1500 of 50000:  tensor(0.0099, grad_fn=<DivBackward0>)\n",
      "2000 of 50000:  tensor(0.0102, grad_fn=<DivBackward0>)\n",
      "2500 of 50000:  tensor(0.0098, grad_fn=<DivBackward0>)\n",
      "3000 of 50000:  tensor(0.0099, grad_fn=<DivBackward0>)\n",
      "3500 of 50000:  tensor(0.0099, grad_fn=<DivBackward0>)\n",
      "4000 of 50000:  tensor(0.0097, grad_fn=<DivBackward0>)\n",
      "4500 of 50000:  tensor(0.0097, grad_fn=<DivBackward0>)\n",
      "5000 of 50000:  tensor(0.0096, grad_fn=<DivBackward0>)\n",
      "5500 of 50000:  tensor(0.0098, grad_fn=<DivBackward0>)\n",
      "6000 of 50000:  tensor(0.0099, grad_fn=<DivBackward0>)\n",
      "6500 of 50000:  tensor(0.0098, grad_fn=<DivBackward0>)\n",
      "7000 of 50000:  tensor(0.0095, grad_fn=<DivBackward0>)\n",
      "7500 of 50000:  tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "8000 of 50000:  tensor(0.0095, grad_fn=<DivBackward0>)\n",
      "8500 of 50000:  tensor(0.0093, grad_fn=<DivBackward0>)\n",
      "9000 of 50000:  tensor(0.0096, grad_fn=<DivBackward0>)\n",
      "9500 of 50000:  tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "10000 of 50000:  tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "10500 of 50000:  tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "11000 of 50000:  tensor(0.0094, grad_fn=<DivBackward0>)\n",
      "11500 of 50000:  tensor(0.0090, grad_fn=<DivBackward0>)\n",
      "12000 of 50000:  tensor(0.0093, grad_fn=<DivBackward0>)\n",
      "12500 of 50000:  tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "13000 of 50000:  tensor(0.0091, grad_fn=<DivBackward0>)\n",
      "13500 of 50000:  tensor(0.0089, grad_fn=<DivBackward0>)\n",
      "14000 of 50000:  tensor(0.0089, grad_fn=<DivBackward0>)\n",
      "14500 of 50000:  tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "15000 of 50000:  tensor(0.0086, grad_fn=<DivBackward0>)\n",
      "15500 of 50000:  tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "16000 of 50000:  tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "16500 of 50000:  tensor(0.0085, grad_fn=<DivBackward0>)\n",
      "17000 of 50000:  tensor(0.0088, grad_fn=<DivBackward0>)\n",
      "17500 of 50000:  tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "18000 of 50000:  tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "18500 of 50000:  tensor(0.0085, grad_fn=<DivBackward0>)\n",
      "19000 of 50000:  tensor(0.0084, grad_fn=<DivBackward0>)\n",
      "19500 of 50000:  tensor(0.0081, grad_fn=<DivBackward0>)\n",
      "20000 of 50000:  tensor(0.0084, grad_fn=<DivBackward0>)\n",
      "20500 of 50000:  tensor(0.0085, grad_fn=<DivBackward0>)\n",
      "21000 of 50000:  tensor(0.0083, grad_fn=<DivBackward0>)\n",
      "21500 of 50000:  tensor(0.0083, grad_fn=<DivBackward0>)\n",
      "22000 of 50000:  tensor(0.0082, grad_fn=<DivBackward0>)\n",
      "22500 of 50000:  tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "23000 of 50000:  tensor(0.0081, grad_fn=<DivBackward0>)\n",
      "23500 of 50000:  tensor(0.0083, grad_fn=<DivBackward0>)\n",
      "24000 of 50000:  tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "24500 of 50000:  tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "25000 of 50000:  tensor(0.0077, grad_fn=<DivBackward0>)\n",
      "25500 of 50000:  tensor(0.0081, grad_fn=<DivBackward0>)\n",
      "26000 of 50000:  tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "26500 of 50000:  tensor(0.0078, grad_fn=<DivBackward0>)\n",
      "27000 of 50000:  tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "27500 of 50000:  tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "28000 of 50000:  tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "28500 of 50000:  tensor(0.0078, grad_fn=<DivBackward0>)\n",
      "29000 of 50000:  tensor(0.0076, grad_fn=<DivBackward0>)\n",
      "29500 of 50000:  tensor(0.0076, grad_fn=<DivBackward0>)\n",
      "30000 of 50000:  tensor(0.0076, grad_fn=<DivBackward0>)\n",
      "30500 of 50000:  tensor(0.0074, grad_fn=<DivBackward0>)\n",
      "31000 of 50000:  tensor(0.0077, grad_fn=<DivBackward0>)\n",
      "31500 of 50000:  tensor(0.0074, grad_fn=<DivBackward0>)\n",
      "32000 of 50000:  tensor(0.0075, grad_fn=<DivBackward0>)\n",
      "32500 of 50000:  tensor(0.0075, grad_fn=<DivBackward0>)\n",
      "33000 of 50000:  tensor(0.0075, grad_fn=<DivBackward0>)\n",
      "33500 of 50000:  tensor(0.0074, grad_fn=<DivBackward0>)\n",
      "34000 of 50000:  tensor(0.0073, grad_fn=<DivBackward0>)\n",
      "34500 of 50000:  tensor(0.0075, grad_fn=<DivBackward0>)\n",
      "35000 of 50000:  tensor(0.0071, grad_fn=<DivBackward0>)\n",
      "35500 of 50000:  tensor(0.0073, grad_fn=<DivBackward0>)\n",
      "36000 of 50000:  tensor(0.0073, grad_fn=<DivBackward0>)\n",
      "36500 of 50000:  tensor(0.0072, grad_fn=<DivBackward0>)\n",
      "37000 of 50000:  tensor(0.0071, grad_fn=<DivBackward0>)\n",
      "37500 of 50000:  tensor(0.0071, grad_fn=<DivBackward0>)\n",
      "38000 of 50000:  tensor(0.0072, grad_fn=<DivBackward0>)\n",
      "38500 of 50000:  tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "39000 of 50000:  tensor(0.0072, grad_fn=<DivBackward0>)\n",
      "39500 of 50000:  tensor(0.0072, grad_fn=<DivBackward0>)\n",
      "40000 of 50000:  tensor(0.0069, grad_fn=<DivBackward0>)\n",
      "40500 of 50000:  tensor(0.0069, grad_fn=<DivBackward0>)\n",
      "41000 of 50000:  tensor(0.0069, grad_fn=<DivBackward0>)\n",
      "41500 of 50000:  tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "42000 of 50000:  tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "42500 of 50000:  tensor(0.0071, grad_fn=<DivBackward0>)\n",
      "43000 of 50000:  tensor(0.0069, grad_fn=<DivBackward0>)\n",
      "43500 of 50000:  tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "44000 of 50000:  tensor(0.0068, grad_fn=<DivBackward0>)\n",
      "44500 of 50000:  tensor(0.0071, grad_fn=<DivBackward0>)\n",
      "45000 of 50000:  tensor(0.0068, grad_fn=<DivBackward0>)\n",
      "45500 of 50000:  tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "46000 of 50000:  tensor(0.0068, grad_fn=<DivBackward0>)\n",
      "46500 of 50000:  tensor(0.0066, grad_fn=<DivBackward0>)\n",
      "47000 of 50000:  tensor(0.0069, grad_fn=<DivBackward0>)\n",
      "47500 of 50000:  tensor(0.0066, grad_fn=<DivBackward0>)\n",
      "48000 of 50000:  tensor(0.0065, grad_fn=<DivBackward0>)\n",
      "48500 of 50000:  tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "49000 of 50000:  tensor(0.0065, grad_fn=<DivBackward0>)\n",
      "49500 of 50000:  tensor(0.0064, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_tot = 0\n",
    "\n",
    "loops = 50000\n",
    "check_every = 500\n",
    "\n",
    "# training loop\n",
    "for i in range(loops):\n",
    "    log_idx = random.randint(1,4)\n",
    "#     log_idx = 4\n",
    "    batch_indices = torch.randint(0,input_contexts[log_idx].shape[0],(batch_size,))\n",
    "\n",
    "    batch = input_contexts[log_idx][batch_indices]\n",
    "\n",
    "    word_length = len(batch[0])\n",
    "\n",
    "    embeds = torch.transpose(all_char_embeds[batch],0,1)\n",
    "\n",
    "    states = [init_state] + [torch.zeros((batch_size,state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((batch_size,embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,batch_size,embed_size))\n",
    "\n",
    "    for j in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,j)\n",
    "\n",
    "    outputs[-1] = states[-1] @ w_so + b_o\n",
    "    \n",
    "    distances = (torch.cdist(outputs,all_char_embeds[:-1]) ** 2).sum(2,keepdim=True)#is actually distances squared\n",
    "        \n",
    "    filtered = torch.where(embeds != 1e10, ((outputs-embeds)**2 / distances), 0)\n",
    "    \n",
    "    loss = filtered.sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in network_params:\n",
    "        p.data -= 2e-4*p.grad\n",
    "        p.grad = None\n",
    "        \n",
    "    loss_tot+= loss/ (batch_size*word_length)\n",
    "    \n",
    "    if i % check_every==0 and i>0:\n",
    "        print(f\"{i} of {loops}: \" , loss_tot / (check_every))\n",
    "        loss_tot = 0\n",
    "#     print('o',outputs)\n",
    "#     print('e',embeds)\n",
    "#     print('wl',word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "17d8265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    word_length = len(word)\n",
    "\n",
    "    embeds = all_char_embeds[word]\n",
    "\n",
    "    states = [init_state]+[torch.zeros((state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,embed_size))\n",
    "\n",
    "    for i in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,i)\n",
    "\n",
    "    return states[-1] @ w_so + b_o\n",
    "\n",
    "\n",
    "def get_next(text):\n",
    "    word = [char_to_int[c] for c in text] +[0]\n",
    "\n",
    "    pred = predict(word)\n",
    "\n",
    "    pred = pred.view(1,embed_size)\n",
    "    dists = torch.cdist(pred,all_char_embeds[:-1])\n",
    "    dists = dists.view(-1)\n",
    "    dists = torch.exp(-5*dists)\n",
    "    dists/=dists.sum()\n",
    "    sampled = (torch.multinomial(dists,1)).item()\n",
    "    return int_to_char[sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "3608a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vne.\n",
      "en.\n",
      "mny.\n",
      "teyyaelynaser.\n",
      "deterny.\n",
      "mrl.\n",
      "ras.\n",
      "mienrltroll.\n",
      "ie.\n",
      "sd.\n",
      "errynil.\n",
      "milntta.\n",
      "iasllnt.\n",
      "moienadtlnlaana.\n",
      "cni.\n",
      "mylltoinralalisllnlh.\n",
      "sodl.\n",
      "eeleeaeray.\n",
      "naeayel.\n",
      "ieeeairte.\n",
      "sa.\n",
      "yaloeeeeieareers.\n",
      "aaini.\n",
      "ta.\n",
      "o.\n",
      "te.\n",
      "lnryrilealesny.\n",
      "mahtttul.\n",
      "a.\n",
      ".\n",
      "tenelloiyiieoi.\n",
      "cennnnienynerirt.\n",
      "sa.\n",
      "hoteaalaaeairterierirlteilyylteraai.\n",
      "tidniha.\n",
      "jrailh.\n",
      "tier.\n",
      "laena.\n",
      "raiea.\n",
      "mnoea.\n",
      "tooetaeilialiimto.\n",
      "mn.\n",
      "vilaenlirieenoetaaaeeevet.\n",
      "aol.\n",
      "oedhvelrnle.\n",
      "sooleueielln.\n",
      "dlteoamasteaooi.\n",
      "mle.\n",
      "menasityieaionaeltiry.\n",
      "sn.\n",
      "mio.\n",
      "teiarnelimslneleosayto.\n",
      "sorinil.\n",
      "dteaelryio.\n",
      "toy.\n",
      "neliyeoereelaoni.\n",
      "u.\n",
      "a.\n",
      "naal.\n",
      "tiaonahnarulnranoomarta.\n",
      "serlomniaalsoemdla.\n",
      "teovvti.\n",
      "mmersd.\n",
      "oairlaonnaehiaaoiten.\n",
      "seet.\n",
      "tryleen.\n",
      "aaieoiaayoaelau.\n",
      "menteai.\n",
      "coye.\n",
      "teoeiaa.\n",
      "rilenrtod.\n",
      "rs.\n",
      "tymr.\n",
      "cneronoaaaede.\n",
      "lroonayrneove.\n",
      "a.\n",
      "tolitaaatataaealse.\n",
      "lidliedaynr.\n",
      "neanaa.\n",
      "vot.\n",
      "l.\n",
      "cynerl.\n",
      "yoasalnninel.\n",
      "tni.\n",
      "mi.\n",
      "tninlea.\n",
      "deivtusl.\n",
      "a.\n",
      "roar.\n",
      "ale.\n",
      "teoi.\n",
      "aymn.\n",
      "eon.\n",
      "etyealeaanm.\n",
      "yeneiaeahian.\n",
      "nmelo.\n",
      ".\n",
      "mynalas.\n",
      "oeieoiryailylaaeearea.\n",
      "mrrnieylnoliorreoolmeaele.\n"
     ]
    }
   ],
   "source": [
    "start_st = ''\n",
    "\n",
    "for _ in range(100):\n",
    "    st = start_st\n",
    "    curr = 'a'\n",
    "    while curr!='.':\n",
    "        curr = get_next(st)\n",
    "        st+=curr\n",
    "    print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "088c8955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6450, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((all_char_embeds[char_to_int['m']]-all_char_embeds[char_to_int['j']])**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "c4258794",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_char_embeds.data [:-1] -= torch.mean(all_char_embeds[:-1],0)\n",
    "all_char_embeds.data [:-1] /= torch.std(all_char_embeds[:-1],0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "228af789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8800,  0.0131,  1.5467, -0.6799], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(all_char_embeds[:-1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "16f2916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5012e-01, -2.4450e-02,  3.9393e-01, -1.2016e-01],\n",
       "        [ 4.5529e-01, -1.7121e-03,  3.3084e-01, -1.9254e-01],\n",
       "        [ 9.5880e-01,  1.1683e+00,  4.5491e-01, -2.1356e-01],\n",
       "        [-2.2185e-01,  2.5530e-01, -2.6817e-01, -7.5573e-01],\n",
       "        [ 8.6706e-01,  1.7468e-01,  4.4619e-01, -1.9205e-02],\n",
       "        [ 4.6325e-01, -2.6519e-02,  3.8783e-01, -1.5155e-01],\n",
       "        [-1.5893e+00,  5.1317e-01, -2.1757e+00,  8.5860e-02],\n",
       "        [-9.4863e-01, -5.7473e-01, -1.8380e+00, -1.5821e+00],\n",
       "        [ 4.0778e-01, -2.8972e-01,  7.4186e-01,  4.2629e-02],\n",
       "        [ 4.4010e-01, -2.5068e-02,  4.3573e-01, -1.1926e-01],\n",
       "        [ 7.2413e-01,  1.6931e-01, -1.0461e+00, -1.2130e+00],\n",
       "        [-5.6255e-01, -1.2972e-01, -7.5269e-01, -7.6305e-01],\n",
       "        [ 4.5623e-01,  1.9689e-02,  3.4889e-01, -7.5090e-02],\n",
       "        [ 1.5951e-01,  1.3316e-01,  2.0722e-02, -1.2357e-01],\n",
       "        [ 4.3361e-01, -4.6162e-02,  3.9439e-01, -9.1754e-02],\n",
       "        [ 5.9844e-01, -1.4042e-01,  4.0913e-01, -1.2199e-01],\n",
       "        [ 8.6843e-01, -5.0983e-02,  2.3596e+00,  6.1432e-01],\n",
       "        [ 1.1143e+00, -1.3181e+00,  2.6156e-01,  9.3619e-01],\n",
       "        [ 3.9992e-01, -3.7503e-02,  3.8186e-01, -3.8121e-02],\n",
       "        [ 3.2739e-01, -2.5106e-01,  1.0105e-01,  1.4927e-02],\n",
       "        [ 3.9125e-01,  1.3341e-01,  2.1064e-01, -3.7430e-01],\n",
       "        [ 9.5646e-01, -1.3999e-01,  8.1060e-01, -4.9808e-02],\n",
       "        [-1.2041e-01, -9.0052e-02,  3.0240e-01,  1.6341e-01],\n",
       "        [-1.0811e-01, -4.3243e+00,  9.4670e-01,  1.8733e+00],\n",
       "        [-3.8632e+00, -1.0689e+00, -2.7038e-01,  1.1699e+00],\n",
       "        [ 3.9289e-01,  5.3795e-02,  5.3304e-01, -2.4455e-01],\n",
       "        [-1.2538e+00, -4.9643e-01,  3.4109e-01, -1.3847e-01],\n",
       "        [ 1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_char_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea083d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
