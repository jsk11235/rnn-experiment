{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf6862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in ./old/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./old/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, filelock, torch\n",
      "Successfully installed filelock-3.12.2 mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1 typing-extensions-4.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.40.0-cp311-cp311-macosx_10_9_universal2.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-macosx_11_0_arm64.whl (63 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.25.0-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./old/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./old/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./old/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.40.0 kiwisolver-1.4.4 matplotlib-3.7.2 numpy-1.25.0 pillow-10.0.0 pyparsing-3.0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8043312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce67c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = open('names.txt','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0053f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "print(names_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8554a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "char_to_int['.'] = 0\n",
    "int_to_char[0] = '.'\n",
    "\n",
    "for char_num in range(ord('a'),ord('z')+1):\n",
    "    integer_representation = char_num-ord('a')+1\n",
    "    char_to_int[chr(char_num)] = integer_representation\n",
    "    int_to_char[integer_representation] = chr(char_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd193dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0853e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "embed_size = 6\n",
    "\n",
    "state_size = 15\n",
    "\n",
    "hidden_size = 30\n",
    "\n",
    "vocab_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "84d731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "char_vector_size = 2\n",
    "input_contexts , input_labels = [[] for _ in range(5)], [[] for _ in range(5)]\n",
    "\n",
    "for name in names_list:\n",
    "    log_padded_length = math.ceil(math.log(len(name))/math.log(2))\n",
    "    padded_length = int(2**log_padded_length)\n",
    "    context = [char_to_int[char] for char in name]  + [0] + [vocab_size-1]*(padded_length-len(name)) \n",
    "    input_contexts[log_padded_length].append(context)\n",
    "#   instead of using labels, we can compare the result to the character vectors to find a likely match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d61aaf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1404, 0.1485, 0.0116, 0.0155, 0.0241, 0.0895, 0.0040, 0.0084, 0.0334,\n",
       "        0.0776, 0.0127, 0.0221, 0.0612, 0.0291, 0.0803, 0.0348, 0.0045, 0.0012,\n",
       "        0.0557, 0.0355, 0.0244, 0.0137, 0.0113, 0.0041, 0.0031, 0.0428, 0.0105,\n",
       "        0.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = [0 for i in range(vocab_size-1)]\n",
    "\n",
    "for log_len in range(1,5):\n",
    "    contexts = input_contexts[log_len]\n",
    "    for c in contexts:\n",
    "        for int_char in c:\n",
    "            if int_char<vocab_size-1:\n",
    "                freqs[int_char] += 1\n",
    "                \n",
    "freqs = torch.tensor(freqs+[0],dtype=torch.float64)\n",
    "freqs/=freqs.sum()\n",
    "\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e63c25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = input_contexts[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40819a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "all_char_embeds = torch.randn((vocab_size,embed_size))\n",
    "\n",
    "all_char_embeds[vocab_size-1] = 10**10\n",
    "\n",
    "w_eh = torch.randn((embed_size, hidden_size)) * 0.5\n",
    "\n",
    "w_sh = torch.randn((state_size, hidden_size)) * 0.5\n",
    "w_so = torch.randn((state_size, embed_size)) *0.5\n",
    "\n",
    "w_hs = torch.randn((hidden_size, state_size)) *0.5\n",
    "\n",
    "b_h = torch.zeros((hidden_size,))\n",
    "b_s = torch.zeros((state_size,))\n",
    "b_o = torch.zeros((embed_size,))\n",
    "\n",
    "init_state = torch.randn((state_size,)) * 0.5\n",
    "\n",
    "network_params = [init_state,w_eh,w_sh,w_so,w_hs,b_h,b_s,b_o,all_char_embeds]\n",
    "\n",
    "for p in network_params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68feafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_and_embed(states , embeds, hiddens, outputs, idx):\n",
    "    hiddens[idx] = 2*torch.sigmoid((states[idx] @ w_sh) + (embeds[idx] @ w_eh) + b_h) -1\n",
    "    states[idx+1] = hiddens[idx] @ w_hs + b_s\n",
    "    outputs[idx] = states[idx] @ w_so + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ed9af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in range(len(input_contexts)):\n",
    "    input_contexts[i] = torch.tensor(input_contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fef2cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "1000 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "1500 of 100000:  tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "2000 of 100000:  tensor(0.0149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "2500 of 100000:  tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "3000 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "3500 of 100000:  tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "4000 of 100000:  tensor(0.0144, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "4500 of 100000:  tensor(0.0150, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "5000 of 100000:  tensor(0.0150, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "5500 of 100000:  tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "6000 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "6500 of 100000:  tensor(0.0148, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "7000 of 100000:  tensor(0.0149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "7500 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "8000 of 100000:  tensor(0.0147, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "8500 of 100000:  tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "9000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "9500 of 100000:  tensor(0.0147, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "10000 of 100000:  tensor(0.0149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "10500 of 100000:  tensor(0.0150, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "11000 of 100000:  tensor(0.0149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "11500 of 100000:  tensor(0.0146, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "12000 of 100000:  tensor(0.0148, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "12500 of 100000:  tensor(0.0150, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "13000 of 100000:  tensor(0.0150, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "13500 of 100000:  tensor(0.0148, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "14000 of 100000:  tensor(0.0149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "14500 of 100000:  tensor(0.0149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "15000 of 100000:  tensor(0.0148, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "15500 of 100000:  tensor(0.0148, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "16000 of 100000:  tensor(0.0146, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "16500 of 100000:  tensor(0.0150, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "17000 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "17500 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "18000 of 100000:  tensor(0.0146, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "18500 of 100000:  tensor(0.0147, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "19000 of 100000:  tensor(0.0144, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "19500 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "20000 of 100000:  tensor(0.0149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "20500 of 100000:  tensor(0.0147, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "21000 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "21500 of 100000:  tensor(0.0147, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "22000 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "22500 of 100000:  tensor(0.0146, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "23000 of 100000:  tensor(0.0148, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "23500 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "24000 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "24500 of 100000:  tensor(0.0146, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "25000 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "25500 of 100000:  tensor(0.0144, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "26000 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "26500 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "27000 of 100000:  tensor(0.0146, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "27500 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "28000 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "28500 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "29000 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "29500 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "30000 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "30500 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "31000 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "31500 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "32000 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "32500 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "33000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "33500 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "34000 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "34500 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "35000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "35500 of 100000:  tensor(0.0144, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "36000 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "36500 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "37000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "37500 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "38000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "38500 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "39000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "39500 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "40000 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "40500 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "41000 of 100000:  tensor(0.0142, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "41500 of 100000:  tensor(0.0143, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "42000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "42500 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "43000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "43500 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "44000 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "44500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "45000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "45500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "46000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "46500 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "47000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "47500 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "48000 of 100000:  tensor(0.0145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "48500 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "49000 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "49500 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "50000 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "50500 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "51000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "51500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "52000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "52500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "53000 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53500 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "54000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "54500 of 100000:  tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "55000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "55500 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "56000 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "56500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "57000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "57500 of 100000:  tensor(0.0140, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "58000 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "58500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "59000 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "59500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "60000 of 100000:  tensor(0.0141, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "60500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "61000 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "61500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "62000 of 100000:  tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "62500 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "63000 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "63500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "64000 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "64500 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "65000 of 100000:  tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "65500 of 100000:  tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "66000 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "66500 of 100000:  tensor(0.0138, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "67000 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "67500 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "68000 of 100000:  tensor(0.0137, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "68500 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "69000 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "69500 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "70000 of 100000:  tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "70500 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "71000 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "71500 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "72000 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "72500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "73000 of 100000:  tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "73500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "74000 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "74500 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "75000 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "75500 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "76000 of 100000:  tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "76500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "77000 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "77500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "78000 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "78500 of 100000:  tensor(0.0139, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "79000 of 100000:  tensor(0.0131, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "79500 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "80000 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "80500 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "81000 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "81500 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "82000 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "82500 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "83000 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "83500 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "84000 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "84500 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "85000 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "85500 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "86000 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "86500 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "87000 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "87500 of 100000:  tensor(0.0129, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "88000 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "88500 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "89000 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "89500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "90000 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "90500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "91000 of 100000:  tensor(0.0135, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "91500 of 100000:  tensor(0.0130, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "92000 of 100000:  tensor(0.0129, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "92500 of 100000:  tensor(0.0131, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "93000 of 100000:  tensor(0.0131, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "93500 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "94000 of 100000:  tensor(0.0133, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "94500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "95000 of 100000:  tensor(0.0131, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "95500 of 100000:  tensor(0.0131, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "96000 of 100000:  tensor(0.0131, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "96500 of 100000:  tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "97000 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "97500 of 100000:  tensor(0.0131, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "98000 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "98500 of 100000:  tensor(0.0132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "99000 of 100000:  tensor(0.0128, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "99500 of 100000:  tensor(0.0129, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_tot = 0\n",
    "\n",
    "loops = 100000\n",
    "check_every = 500\n",
    "\n",
    "# training loop\n",
    "for i in range(loops):\n",
    "    log_idx = random.randint(1,4)\n",
    "#     log_idx = 4\n",
    "    batch_indices = torch.randint(0,input_contexts[log_idx].shape[0],(batch_size,))\n",
    "\n",
    "    batch = input_contexts[log_idx][batch_indices]\n",
    "\n",
    "    word_length = len(batch[0])\n",
    "\n",
    "    embeds = torch.transpose(all_char_embeds[batch],0,1)\n",
    "    \n",
    "    factors = torch.where(freqs > 0,1/(freqs+1e-18),0)\n",
    "    \n",
    "    factors[:-1] /= factors[:-1].mean()\n",
    "    \n",
    "    adjustment_factors = torch.transpose(factors[batch],0,1)\n",
    "    \n",
    "    adjustment_factors = adjustment_factors.view((word_length,batch_size,1))\n",
    "    \n",
    "    adjustment_factors[:-1] /= adjustment_factors[:-1].mean()\n",
    "#     print(adjustment_factors , embeds.shape)\n",
    "\n",
    "    states = [init_state] + [torch.zeros((batch_size,state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((batch_size,embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,batch_size,embed_size))\n",
    "\n",
    "    for j in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,j)\n",
    "\n",
    "    outputs[-1] = states[-1] @ w_so + b_o\n",
    "    \n",
    "    distances = (torch.cdist(outputs,all_char_embeds[:-1]) ** 2).sum(2,keepdim=True)#is actually distances squared\n",
    "        \n",
    "    filtered = torch.where(embeds != 1e10, ((outputs-embeds)**2 / distances), 0)\n",
    "    \n",
    "    ones = torch.where(embeds != 1e10, 1, 0)\n",
    "    \n",
    "    loss = (filtered*adjustment_factors).sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in network_params:\n",
    "        p.data -= 1e-3*p.grad\n",
    "        p.grad = None\n",
    "        \n",
    "    loss_tot+= loss/ adjustment_factors.sum()\n",
    "    if i % check_every==0 and i>0:\n",
    "        print(f\"{i} of {loops}: \" , loss_tot / (check_every))\n",
    "        loss_tot = 0\n",
    "#     print('o',outputs)\n",
    "#     print('e',embeds)\n",
    "#     print('wl',word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17d8265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    word_length = len(word)\n",
    "\n",
    "    embeds = all_char_embeds[word]\n",
    "\n",
    "    states = [init_state]+[torch.zeros((state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,embed_size))\n",
    "\n",
    "    for i in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,i)\n",
    "\n",
    "    return states[-1] @ w_so + b_o\n",
    "\n",
    "\n",
    "def get_next(text):\n",
    "    word = [char_to_int[c] for c in text] +[0]\n",
    "\n",
    "    pred = predict(word)\n",
    "\n",
    "    pred = pred.view(1,embed_size)\n",
    "    dists = torch.cdist(pred,all_char_embeds[:-1])\n",
    "    dists = dists.view(-1)\n",
    "    dists = torch.exp(-dists)\n",
    "    dists/=dists.sum()\n",
    "    sampled = (torch.multinomial(dists,1)).item()\n",
    "    return int_to_char[sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3608a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jklvqgtooy.\n",
      "jfhdafcan.\n",
      "jdslrewosme.\n",
      "jweduevre.\n",
      "jzokyz.\n",
      "jopcparcxrnjor.\n",
      "jacglhrowt.\n",
      "jarwgye.\n",
      "jcusaufwln.\n",
      "jhewpblmsv.\n",
      "jfyjtcbdkcmhg.\n",
      "jpeyxtlwpfdrvn.\n",
      "jlburdrcax.\n",
      "jzvxgmehua.\n",
      "jkazrezzil.\n",
      "jfxluimfin.\n",
      "jpwqojdlyru.\n",
      "jjavihbuxv.\n",
      "jmhtephwhy.\n",
      "jxeqoye.\n",
      "jzgkrhzbxlgot.\n",
      "jigpjydwbe.\n",
      "jltmoewlbzqi.\n",
      "jledhmjya.\n",
      "jdapumwmjmn.\n",
      "jejpgurxlqxtioh.\n",
      "jjismqyaj.\n",
      "jfogjxzwpa.\n",
      "jubeuftgftn.\n",
      "jussoyv.\n",
      "jwwryo.\n",
      "jigjpnrjhk.\n",
      "jigdrtrbcq.\n",
      "jfnoibun.\n",
      "jiocjintao.\n",
      "juhghyit.\n",
      "jkvawscuxb.\n",
      "jpswie.\n",
      "jetporeby.\n",
      "jqnygvim.\n",
      "jpepqrbaak.\n",
      "jjbhbiwzqon.\n",
      "jumdvstguh.\n",
      "jriggupyu.\n",
      "jdpdnvjvtfa.\n",
      "jqgngbtwkxqo.\n",
      "jkpkextgvdl.\n",
      "jjiqmuqoly.\n",
      "jvkhnhej.\n",
      "jsfshljfqbv.\n",
      "jovoltyoo.\n",
      "jtnedkbuws.\n",
      "jknxrvpri.\n",
      "jkhjetnlwdw.\n",
      "jxruyo.\n",
      "jdsvotmos.\n",
      "jxjnpjkvmcadphh.\n",
      "jewqivuwttat.\n",
      "josgpknaly.\n",
      "jqffpeikou.\n",
      "jhhdfxruhw.\n",
      "jwcrorcyu.\n",
      "jolftsgaz.\n",
      "jhztym.\n",
      "jvlsfxrtiln.\n",
      "jjhldnknpiil.\n",
      "jasmfjhdlzn.\n",
      "jqmhbsdkzis.\n",
      "jvtvrzbwak.\n",
      "jynrleah.\n",
      "jcetqppkpe.\n",
      "jtocofzben.\n",
      "jcnhigvae.\n",
      "jshiqnomoe.\n",
      "jofbapquxx.\n",
      "jtpgjpojko.\n",
      "jozttwlvgpun.\n",
      "jbuicxbton.\n",
      "jxnywxmzgr.\n",
      "jvosquhzxwr.\n",
      "jytiwmrpkkluqvo.\n",
      "jthvaulol.\n",
      "jtmyojmmot.\n",
      "jupqyimbpxw.\n",
      "jdjurzsbzjcst.\n",
      "jwfushuxudn.\n",
      "jhfkgblqsh.\n",
      "juvbbvatfs.\n",
      "jephzjhzlwr.\n",
      "jucomuleov.\n",
      "jqfgnhabwtgg.\n",
      "jhkkdrljif.\n",
      "jggvepzijr.\n",
      "jletaciky.\n",
      "juggmwtfhh.\n",
      "jifvegqwkzufdy.\n",
      "jxkgfhbjpyn.\n",
      "jashibqxflph.\n",
      "jliljotdqy.\n",
      "jxtfbkopugy.\n"
     ]
    }
   ],
   "source": [
    "start_st = 'j'\n",
    "\n",
    "for _ in range(100):\n",
    "    st = start_st\n",
    "    curr = 'a'\n",
    "    while curr!='.':\n",
    "        curr = get_next(st)\n",
    "        st+=curr\n",
    "    print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "088c8955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9190e-05, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((all_char_embeds[char_to_int['a']]-all_char_embeds[char_to_int['e']])**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16f2916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1404e-02, -3.1502e-01,  3.8437e-01,  2.2421e-01, -4.5370e-02,\n",
       "          1.1276e-01],\n",
       "        [ 4.5207e-02, -3.1540e-01,  3.7890e-01,  2.3027e-01, -3.9489e-02,\n",
       "          1.1035e-01],\n",
       "        [-1.9714e-01, -1.2698e-01,  2.5729e-01,  3.4796e-01, -5.0878e-03,\n",
       "          5.1886e-03],\n",
       "        [-1.1072e-02, -3.5110e-01,  3.7590e-01,  2.3563e-01, -7.8479e-02,\n",
       "          8.7188e-02],\n",
       "        [ 3.8594e-02, -2.9808e-01,  4.2518e-01,  2.1967e-01, -2.6467e-02,\n",
       "          9.5366e-02],\n",
       "        [ 4.3529e-02, -3.1508e-01,  3.8704e-01,  2.2813e-01, -4.0856e-02,\n",
       "          1.0848e-01],\n",
       "        [ 7.6546e-01,  3.9753e-01, -3.2336e+00, -2.1769e-01,  1.5096e-01,\n",
       "          2.4524e+00],\n",
       "        [ 1.4561e-01, -3.7959e-02, -3.3408e-01,  2.4587e-01, -2.6998e-01,\n",
       "          9.5122e-01],\n",
       "        [ 2.9950e-02, -3.1685e-01,  4.2429e-01,  2.0591e-01, -2.3509e-02,\n",
       "          7.8233e-02],\n",
       "        [ 4.0571e-02, -3.1500e-01,  3.9491e-01,  2.2562e-01, -3.9184e-02,\n",
       "          1.0424e-01],\n",
       "        [ 7.5062e-02, -3.5887e-01,  3.6286e-01,  3.4364e-01, -4.4374e-02,\n",
       "          9.2274e-02],\n",
       "        [ 6.9342e-02, -3.0707e-01,  3.8972e-01,  2.7185e-01, -3.8190e-02,\n",
       "          9.5443e-02],\n",
       "        [ 4.1449e-02, -3.1527e-01,  3.9150e-01,  2.2623e-01, -3.9586e-02,\n",
       "          1.0474e-01],\n",
       "        [ 4.2842e-02, -3.2207e-01,  3.9007e-01,  2.2910e-01, -2.9004e-02,\n",
       "          9.9347e-02],\n",
       "        [ 3.8880e-02, -3.1589e-01,  3.9263e-01,  2.2463e-01, -4.1636e-02,\n",
       "          1.0811e-01],\n",
       "        [ 3.5323e-02, -3.1731e-01,  4.0685e-01,  2.2068e-01, -3.0827e-02,\n",
       "          9.4362e-02],\n",
       "        [ 5.9327e-01,  2.6693e-01, -2.2447e+00,  1.3902e-03, -1.9422e-02,\n",
       "          5.9595e-01],\n",
       "        [ 2.0321e+00,  4.9897e+00, -2.8866e+00, -1.6551e+00,  4.1135e+00,\n",
       "         -2.7112e+00],\n",
       "        [ 3.9805e-02, -3.1676e-01,  3.9484e-01,  2.2550e-01, -3.6160e-02,\n",
       "          1.0289e-01],\n",
       "        [ 4.0956e-02, -3.1580e-01,  4.0578e-01,  2.2334e-01, -3.5166e-02,\n",
       "          9.8833e-02],\n",
       "        [ 3.7682e-02, -3.1238e-01,  4.1578e-01,  2.0683e-01, -3.5363e-02,\n",
       "          9.0807e-02],\n",
       "        [-7.9006e-02, -3.4744e-01,  5.3662e-01,  1.1624e-01, -2.6701e-02,\n",
       "          1.0421e-01],\n",
       "        [ 7.0380e-02, -3.9622e-01,  1.2057e-02,  3.0313e-01,  6.7070e-02,\n",
       "          3.7276e-02],\n",
       "        [ 1.2458e+00,  6.1335e-02,  1.2884e-01,  1.9628e+00, -1.8554e-02,\n",
       "         -6.4176e-01],\n",
       "        [ 5.3214e-01,  1.6664e+00, -3.9561e+00, -3.1645e+00, -2.9631e+00,\n",
       "         -4.7933e-01],\n",
       "        [ 3.6084e-02, -3.1802e-01,  4.1432e-01,  2.1769e-01, -2.9644e-02,\n",
       "          9.1092e-02],\n",
       "        [ 7.3244e-01, -1.1435e-01,  5.9190e-02, -1.0250e-01,  2.7890e-01,\n",
       "          2.4015e-01],\n",
       "        [ 1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10,\n",
       "          1.0000e+10]], requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_char_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea083d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
