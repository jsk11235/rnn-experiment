{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf6862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.8/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.8/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.8/site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "c8043312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "3ce67c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = open('names.txt','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "0053f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "print(names_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "8554a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "char_to_int['.'] = 0\n",
    "int_to_char[0] = '.'\n",
    "\n",
    "for char_num in range(ord('a'),ord('z')+1):\n",
    "    integer_representation = char_num-ord('a')+1\n",
    "    char_to_int[chr(char_num)] = integer_representation\n",
    "    int_to_char[integer_representation] = chr(char_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "cd193dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "0853e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "embed_size = 4\n",
    "\n",
    "state_size = 10\n",
    "\n",
    "hidden_size = 25\n",
    "\n",
    "vocab_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "84d731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "char_vector_size = 2\n",
    "input_contexts , input_labels = [[] for _ in range(5)], [[] for _ in range(5)]\n",
    "\n",
    "for name in names_list:\n",
    "    log_padded_length = math.ceil(math.log(len(name))/math.log(2))\n",
    "    padded_length = int(2**log_padded_length)\n",
    "    context = [char_to_int[char] for char in name]  + [0] + [vocab_size-1]*(padded_length-len(name)) \n",
    "    input_contexts[log_padded_length].append(context)\n",
    "#   instead of using labels, we can compare the result to the character vectors to find a likely match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "e63c25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = input_contexts[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "40819a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "all_char_embeds = torch.randn((vocab_size,embed_size))\n",
    "\n",
    "all_char_embeds[vocab_size-1] = 10**10\n",
    "\n",
    "w_eh = torch.randn((embed_size, hidden_size)) * 0.5\n",
    "\n",
    "w_sh = torch.randn((state_size, hidden_size)) * 0.5\n",
    "w_so = torch.randn((state_size, embed_size)) *0.5\n",
    "\n",
    "w_hs = torch.randn((hidden_size, state_size)) *0.5\n",
    "\n",
    "b_h = torch.zeros((hidden_size,))\n",
    "b_s = torch.zeros((state_size,))\n",
    "b_o = torch.zeros((embed_size,))\n",
    "\n",
    "init_state = torch.randn((state_size,)) * 0.5\n",
    "\n",
    "network_params = [init_state,w_eh,w_sh,w_so,w_hs,b_h,b_s,b_o,all_char_embeds]\n",
    "\n",
    "for p in network_params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "68feafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_and_embed(states , embeds, hiddens, outputs, idx):\n",
    "    hiddens[idx] = 2*torch.sigmoid((states[idx] @ w_sh) + (embeds[idx] @ w_eh) + b_h) -1\n",
    "    states[idx+1] = hiddens[idx] @ w_hs + b_s\n",
    "    outputs[idx] = states[idx] @ w_so + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "0ed9af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in range(len(input_contexts)):\n",
    "    input_contexts[i] = torch.tensor(input_contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "fef2cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 of 50000:  tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "1000 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "1500 of 50000:  tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "2000 of 50000:  tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "2500 of 50000:  tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "3000 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "3500 of 50000:  tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "4000 of 50000:  tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "4500 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "5000 of 50000:  tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "5500 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "6000 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "6500 of 50000:  tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "7000 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "7500 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "8000 of 50000:  tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "8500 of 50000:  tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "9000 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "9500 of 50000:  tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "10000 of 50000:  tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "10500 of 50000:  tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "11000 of 50000:  tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "11500 of 50000:  tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "12000 of 50000:  tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "12500 of 50000:  tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "13000 of 50000:  tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "13500 of 50000:  tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "14000 of 50000:  tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "14500 of 50000:  tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "15000 of 50000:  tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "15500 of 50000:  tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "16000 of 50000:  tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "16500 of 50000:  tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "17000 of 50000:  tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "17500 of 50000:  tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "18000 of 50000:  tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "18500 of 50000:  tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "19000 of 50000:  tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "19500 of 50000:  tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "20000 of 50000:  tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "20500 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "21000 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "21500 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "22000 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "22500 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "23000 of 50000:  tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "23500 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "24000 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "24500 of 50000:  tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "25000 of 50000:  tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "25500 of 50000:  tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "26000 of 50000:  tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "26500 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "27000 of 50000:  tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "27500 of 50000:  tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "28000 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "28500 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "29000 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "29500 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "30000 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "30500 of 50000:  tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "31000 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "31500 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "32000 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "32500 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "33000 of 50000:  tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "33500 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "34000 of 50000:  tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "34500 of 50000:  tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "35000 of 50000:  tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "35500 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "36000 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "36500 of 50000:  tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "37000 of 50000:  tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "37500 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "38000 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "38500 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "39000 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "39500 of 50000:  tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "40000 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "40500 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "41000 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "41500 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "42000 of 50000:  tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "42500 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "43000 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "43500 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "44000 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "44500 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "45000 of 50000:  tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "45500 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "46000 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "46500 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "47000 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "47500 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "48000 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n",
      "48500 of 50000:  tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "49000 of 50000:  tensor(0.0006, grad_fn=<DivBackward0>)\n",
      "49500 of 50000:  tensor(0.0007, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_tot = 0\n",
    "\n",
    "loops = 50000\n",
    "check_every = 500\n",
    "\n",
    "# training loop\n",
    "for i in range(loops):\n",
    "    log_idx = random.randint(1,4)\n",
    "#     log_idx = 4\n",
    "    batch_indices = torch.randint(0,input_contexts[log_idx].shape[0],(batch_size,))\n",
    "\n",
    "    batch = input_contexts[log_idx][batch_indices]\n",
    "\n",
    "    word_length = len(batch[0])\n",
    "\n",
    "    embeds = torch.transpose(all_char_embeds[batch],0,1)\n",
    "\n",
    "    states = [init_state] + [torch.zeros((batch_size,state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((batch_size,embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,batch_size,embed_size))\n",
    "\n",
    "    for j in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,j)\n",
    "\n",
    "    outputs[-1] = states[-1] @ w_so + b_o\n",
    "    \n",
    "    distances = torch.cdist(outputs,all_char_embeds[:-1]).sum(2,keepdim=True)\n",
    "        \n",
    "    filtered = torch.where(embeds != 1e10, ((outputs-embeds)**2 / distances), 0)\n",
    "    \n",
    "    loss = filtered.sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in network_params:\n",
    "        p.data -= 1e-4*p.grad\n",
    "        p.grad = None\n",
    "        \n",
    "    loss_tot+= loss/ (batch_size*word_length)\n",
    "    \n",
    "    if i % check_every==0 and i>0:\n",
    "        print(f\"{i} of {loops}: \" , loss_tot / (check_every))\n",
    "        loss_tot = 0\n",
    "#     print('o',outputs)\n",
    "#     print('e',embeds)\n",
    "#     print('wl',word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "17d8265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    word_length = len(word)\n",
    "\n",
    "    embeds = all_char_embeds[word]\n",
    "\n",
    "    states = [init_state]+[torch.zeros((state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,embed_size))\n",
    "\n",
    "    for i in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,i)\n",
    "\n",
    "    return states[-1] @ w_so + b_o\n",
    "\n",
    "\n",
    "def get_next(text):\n",
    "    word = [char_to_int[c] for c in text] +[0]\n",
    "\n",
    "    pred = predict(word)\n",
    "\n",
    "    pred = pred.view(1,embed_size)\n",
    "    dists = torch.cdist(pred,all_char_embeds[:-1])\n",
    "    dists = dists.view(-1)\n",
    "    dists = torch.exp(-1000*dists)\n",
    "    dists/=dists.sum()\n",
    "    sampled = (torch.multinomial(dists,1)).item()\n",
    "    return int_to_char[sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jd.\n",
      "jo.\n"
     ]
    }
   ],
   "source": [
    "start_st = 'j'\n",
    "\n",
    "for _ in range(100):\n",
    "    st = start_st\n",
    "    curr = 'a'\n",
    "    while curr!='.':\n",
    "        curr = get_next(st)\n",
    "        st+=curr\n",
    "    print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "088c8955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0244, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((all_char_embeds[char_to_int['u']]-all_char_embeds[char_to_int['d']])**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "c4258794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9664e-01, -6.0726e-02,  3.1658e-01, -7.4424e-02],\n",
       "        [-2.4544e-01, -7.9831e-02,  2.8781e-01, -7.6645e-02],\n",
       "        [-1.7123e-02, -7.6159e-02,  5.4805e-01,  2.1402e-01],\n",
       "        [ 8.9724e-02, -8.4789e-04,  4.8525e-02, -1.9236e-01],\n",
       "        [-2.0644e-01, -3.7802e-02,  4.2947e-01,  9.9446e-02],\n",
       "        [-2.7876e-01, -9.1170e-02,  2.9630e-01, -7.1531e-02],\n",
       "        [ 1.0480e+00, -2.4380e-01, -1.5023e+00, -8.5290e-01],\n",
       "        [-2.3502e-01,  3.8689e-01,  8.7651e-01, -2.7298e-01],\n",
       "        [-4.1980e-01, -6.3887e-02,  2.0647e-01, -8.4796e-02],\n",
       "        [-2.9296e-01, -1.0149e-01,  3.0774e-01, -6.4426e-02],\n",
       "        [ 4.1933e-02, -2.1295e-01,  1.5177e-01,  2.2886e-02],\n",
       "        [-1.4921e-01, -7.5653e-02,  2.3434e-01, -3.9551e-01],\n",
       "        [-2.7345e-01, -1.1771e-01,  3.0814e-01, -8.4988e-02],\n",
       "        [-2.2740e-01, -1.3531e-01,  1.3570e-01, -1.5739e-01],\n",
       "        [-3.0604e-01, -8.3162e-02,  3.2461e-01, -7.4180e-02],\n",
       "        [-2.3206e-01, -1.6435e-01,  3.6302e-01, -2.4898e-02],\n",
       "        [-9.5440e-01,  4.7238e-02,  1.2014e+00, -1.1563e-02],\n",
       "        [ 1.9769e+00,  6.6366e-02,  9.3301e-01, -6.9505e-01],\n",
       "        [-2.7745e-01, -8.2848e-02,  3.3776e-01, -9.6023e-02],\n",
       "        [-2.5505e-01,  4.6934e-02,  3.0532e-01, -9.6767e-02],\n",
       "        [-3.8015e-01, -1.0535e-02,  2.9300e-01, -1.1528e-02],\n",
       "        [-3.9075e-01, -2.2507e-01,  4.8178e-01,  2.2580e-01],\n",
       "        [ 5.3255e-02, -3.3201e-01, -4.2325e-01, -3.5514e-01],\n",
       "        [-1.2385e+00,  1.4007e+00,  2.0268e-01,  1.7199e-01],\n",
       "        [ 4.4863e-01,  1.0399e+00,  8.7026e-01,  7.4335e-01],\n",
       "        [-2.5271e-01, -1.1023e-01,  3.9221e-01, -5.0026e-02],\n",
       "        [-5.5410e-01,  4.7035e-02,  4.5822e-01, -6.0289e-01],\n",
       "        [ 1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_char_embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9ebd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
