{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf6862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in ./old/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./old/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, filelock, torch\n",
      "Successfully installed filelock-3.12.2 mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1 typing-extensions-4.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.40.0-cp311-cp311-macosx_10_9_universal2.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-macosx_11_0_arm64.whl (63 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.25.0-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./old/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./old/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./old/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.40.0 kiwisolver-1.4.4 matplotlib-3.7.2 numpy-1.25.0 pillow-10.0.0 pyparsing-3.0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c8043312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3ce67c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = open('names.txt','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0053f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "print(names_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8554a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "char_to_int['.'] = 0\n",
    "int_to_char[0] = '.'\n",
    "\n",
    "for char_num in range(ord('a'),ord('z')+1):\n",
    "    integer_representation = char_num-ord('a')+1\n",
    "    char_to_int[chr(char_num)] = integer_representation\n",
    "    int_to_char[integer_representation] = chr(char_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0853e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "embed_size = 7\n",
    "\n",
    "state_size = 40\n",
    "\n",
    "hidden_size = 200\n",
    "\n",
    "vocab_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "84d731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "char_vector_size = 2\n",
    "input_contexts , input_labels = [[] for _ in range(5)], [[] for _ in range(5)]\n",
    "\n",
    "for name in names_list:\n",
    "    log_padded_length = math.ceil(math.log(len(name))/math.log(2))\n",
    "    padded_length = int(2**log_padded_length)\n",
    "    context = [char_to_int[char] for char in name]  + [0] + [vocab_size-1]*(padded_length-len(name)) \n",
    "    input_contexts[log_padded_length].append(context)\n",
    "#   instead of using labels, we can compare the result to the character vectors to find a likely match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4a4e5cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1404, 0.1485, 0.0116, 0.0155, 0.0241, 0.0895, 0.0040, 0.0084, 0.0334,\n",
       "        0.0776, 0.0127, 0.0221, 0.0612, 0.0291, 0.0803, 0.0348, 0.0045, 0.0012,\n",
       "        0.0557, 0.0355, 0.0244, 0.0137, 0.0113, 0.0041, 0.0031, 0.0428, 0.0105,\n",
       "        0.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = [0 for i in range(vocab_size-1)]\n",
    "\n",
    "for log_len in range(1,5):\n",
    "    contexts = input_contexts[log_len]\n",
    "    for c in contexts:\n",
    "        for int_char in c:\n",
    "            if int_char<vocab_size-1:\n",
    "                freqs[int_char] += 1\n",
    "                \n",
    "freqs = torch.tensor(freqs+[0],dtype=torch.float64)\n",
    "freqs/=freqs.sum()\n",
    "\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e63c25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = input_contexts[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "40819a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "all_char_embeds = torch.randn((vocab_size,embed_size))\n",
    "\n",
    "all_char_embeds[vocab_size-1] = 10**10\n",
    "\n",
    "w_eh = torch.randn((embed_size, hidden_size)) * 0.5\n",
    "\n",
    "w_sh = torch.randn((state_size, hidden_size)) * 0.5\n",
    "w_so = torch.randn((state_size, embed_size)) *0.5\n",
    "\n",
    "w_hs = torch.randn((hidden_size, state_size)) *0.5\n",
    "\n",
    "b_h = torch.zeros((hidden_size,))\n",
    "b_s = torch.zeros((state_size,))\n",
    "b_o = torch.zeros((embed_size,))\n",
    "\n",
    "init_state = 2*torch.sigmoid(torch.randn((state_size,)))\n",
    "\n",
    "network_params = [init_state,w_eh,w_sh,w_so,w_hs,b_h,b_s,b_o,all_char_embeds]\n",
    "\n",
    "for p in network_params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "68feafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_and_embed(states , embeds, hiddens, outputs, idx):\n",
    "    hiddens[idx] = 2*torch.sigmoid((states[idx] @ w_sh) + (embeds[idx] @ w_eh) + b_h) -1\n",
    "    states[idx+1] = 2*torch.sigmoid(hiddens[idx] @ w_hs + b_s) - 1\n",
    "    outputs[idx] = states[idx] @ w_so + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0ed9af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in range(len(input_contexts)):\n",
    "    input_contexts[i] = torch.tensor(input_contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fef2cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 of 100000:  tensor(0.0367, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "1000 of 100000:  tensor(0.0364, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "1500 of 100000:  tensor(0.0361, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "2000 of 100000:  tensor(0.0358, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "2500 of 100000:  tensor(0.0356, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "3000 of 100000:  tensor(0.0355, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "3500 of 100000:  tensor(0.0352, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "4000 of 100000:  tensor(0.0352, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "4500 of 100000:  tensor(0.0350, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "5000 of 100000:  tensor(0.0346, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "5500 of 100000:  tensor(0.0347, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "6000 of 100000:  tensor(0.0344, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "6500 of 100000:  tensor(0.0342, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "7000 of 100000:  tensor(0.0341, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "7500 of 100000:  tensor(0.0338, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "8000 of 100000:  tensor(0.0336, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "8500 of 100000:  tensor(0.0331, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "9000 of 100000:  tensor(0.0324, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "9500 of 100000:  tensor(0.0321, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "10000 of 100000:  tensor(0.0318, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "10500 of 100000:  tensor(0.0317, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "11000 of 100000:  tensor(0.0316, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "11500 of 100000:  tensor(0.0314, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "12000 of 100000:  tensor(0.0313, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "12500 of 100000:  tensor(0.0313, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "13000 of 100000:  tensor(0.0312, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "13500 of 100000:  tensor(0.0310, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "14000 of 100000:  tensor(0.0308, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "14500 of 100000:  tensor(0.0308, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "15000 of 100000:  tensor(0.0306, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "15500 of 100000:  tensor(0.0308, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "16000 of 100000:  tensor(0.0303, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "16500 of 100000:  tensor(0.0303, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "17000 of 100000:  tensor(0.0305, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "17500 of 100000:  tensor(0.0303, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "18000 of 100000:  tensor(0.0299, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "18500 of 100000:  tensor(0.0298, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "19000 of 100000:  tensor(0.0298, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "19500 of 100000:  tensor(0.0293, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "20000 of 100000:  tensor(0.0294, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "20500 of 100000:  tensor(0.0296, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "21000 of 100000:  tensor(0.0295, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "21500 of 100000:  tensor(0.0294, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "22000 of 100000:  tensor(0.0291, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "22500 of 100000:  tensor(0.0290, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "23000 of 100000:  tensor(0.0289, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "23500 of 100000:  tensor(0.0291, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "24000 of 100000:  tensor(0.0289, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "24500 of 100000:  tensor(0.0286, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "25000 of 100000:  tensor(0.0287, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "25500 of 100000:  tensor(0.0286, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "26000 of 100000:  tensor(0.0284, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "26500 of 100000:  tensor(0.0284, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "27000 of 100000:  tensor(0.0284, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "27500 of 100000:  tensor(0.0286, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "28000 of 100000:  tensor(0.0281, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "28500 of 100000:  tensor(0.0282, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "29000 of 100000:  tensor(0.0282, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "29500 of 100000:  tensor(0.0280, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "30000 of 100000:  tensor(0.0280, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "30500 of 100000:  tensor(0.0283, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "31000 of 100000:  tensor(0.0279, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "31500 of 100000:  tensor(0.0276, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "32000 of 100000:  tensor(0.0276, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "32500 of 100000:  tensor(0.0279, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "33000 of 100000:  tensor(0.0277, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "33500 of 100000:  tensor(0.0276, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "34000 of 100000:  tensor(0.0274, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "34500 of 100000:  tensor(0.0279, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "35000 of 100000:  tensor(0.0274, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "35500 of 100000:  tensor(0.0275, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "36000 of 100000:  tensor(0.0272, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "36500 of 100000:  tensor(0.0273, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "37000 of 100000:  tensor(0.0272, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "37500 of 100000:  tensor(0.0272, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "38000 of 100000:  tensor(0.0270, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "38500 of 100000:  tensor(0.0271, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "39000 of 100000:  tensor(0.0269, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "39500 of 100000:  tensor(0.0270, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "40000 of 100000:  tensor(0.0267, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "40500 of 100000:  tensor(0.0268, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "41000 of 100000:  tensor(0.0266, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "41500 of 100000:  tensor(0.0267, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "42000 of 100000:  tensor(0.0268, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "42500 of 100000:  tensor(0.0269, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "43000 of 100000:  tensor(0.0264, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "43500 of 100000:  tensor(0.0265, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "44000 of 100000:  tensor(0.0265, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "44500 of 100000:  tensor(0.0266, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "45000 of 100000:  tensor(0.0262, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "45500 of 100000:  tensor(0.0262, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "46000 of 100000:  tensor(0.0259, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "46500 of 100000:  tensor(0.0259, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "47000 of 100000:  tensor(0.0260, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "47500 of 100000:  tensor(0.0262, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "48000 of 100000:  tensor(0.0259, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "48500 of 100000:  tensor(0.0259, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "49000 of 100000:  tensor(0.0259, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "49500 of 100000:  tensor(0.0257, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "50000 of 100000:  tensor(0.0258, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "50500 of 100000:  tensor(0.0256, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "51000 of 100000:  tensor(0.0260, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "51500 of 100000:  tensor(0.0257, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "52000 of 100000:  tensor(0.0257, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "52500 of 100000:  tensor(0.0258, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "53000 of 100000:  tensor(0.0252, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53500 of 100000:  tensor(0.0255, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "54000 of 100000:  tensor(0.0255, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "54500 of 100000:  tensor(0.0254, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "55000 of 100000:  tensor(0.0251, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "55500 of 100000:  tensor(0.0254, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "56000 of 100000:  tensor(0.0251, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "56500 of 100000:  tensor(0.0251, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "57000 of 100000:  tensor(0.0248, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "57500 of 100000:  tensor(0.0250, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "58000 of 100000:  tensor(0.0253, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "58500 of 100000:  tensor(0.0246, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "59000 of 100000:  tensor(0.0248, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "59500 of 100000:  tensor(0.0253, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "60000 of 100000:  tensor(0.0246, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "60500 of 100000:  tensor(0.0247, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "61000 of 100000:  tensor(0.0246, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "61500 of 100000:  tensor(0.0245, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "62000 of 100000:  tensor(0.0247, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "62500 of 100000:  tensor(0.0243, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "63000 of 100000:  tensor(0.0245, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "63500 of 100000:  tensor(0.0244, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "64000 of 100000:  tensor(0.0243, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "64500 of 100000:  tensor(0.0246, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "65000 of 100000:  tensor(0.0244, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "65500 of 100000:  tensor(0.0243, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "66000 of 100000:  tensor(0.0242, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "66500 of 100000:  tensor(0.0239, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "67000 of 100000:  tensor(0.0241, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "67500 of 100000:  tensor(0.0241, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "68000 of 100000:  tensor(0.0242, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "68500 of 100000:  tensor(0.0243, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "69000 of 100000:  tensor(0.0242, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "69500 of 100000:  tensor(0.0241, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "70000 of 100000:  tensor(0.0240, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "70500 of 100000:  tensor(0.0237, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "71000 of 100000:  tensor(0.0238, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "71500 of 100000:  tensor(0.0233, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "72000 of 100000:  tensor(0.0236, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "72500 of 100000:  tensor(0.0238, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "73000 of 100000:  tensor(0.0237, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "73500 of 100000:  tensor(0.0236, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "74000 of 100000:  tensor(0.0237, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "74500 of 100000:  tensor(0.0234, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "75000 of 100000:  tensor(0.0237, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "75500 of 100000:  tensor(0.0235, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "76000 of 100000:  tensor(0.0231, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "76500 of 100000:  tensor(0.0235, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "77000 of 100000:  tensor(0.0231, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "77500 of 100000:  tensor(0.0234, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "78000 of 100000:  tensor(0.0230, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "78500 of 100000:  tensor(0.0233, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "79000 of 100000:  tensor(0.0233, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "79500 of 100000:  tensor(0.0236, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "80000 of 100000:  tensor(0.0232, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "80500 of 100000:  tensor(0.0232, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "81000 of 100000:  tensor(0.0231, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "81500 of 100000:  tensor(0.0232, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "82000 of 100000:  tensor(0.0233, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "82500 of 100000:  tensor(0.0230, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "83000 of 100000:  tensor(0.0226, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "83500 of 100000:  tensor(0.0229, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "84000 of 100000:  tensor(0.0234, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "84500 of 100000:  tensor(0.0231, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "85000 of 100000:  tensor(0.0230, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "85500 of 100000:  tensor(0.0226, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "86000 of 100000:  tensor(0.0226, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "86500 of 100000:  tensor(0.0231, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "87000 of 100000:  tensor(0.0228, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "87500 of 100000:  tensor(0.0227, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "88000 of 100000:  tensor(0.0224, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "88500 of 100000:  tensor(0.0227, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "89000 of 100000:  tensor(0.0224, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "89500 of 100000:  tensor(0.0223, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "90000 of 100000:  tensor(0.0226, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "90500 of 100000:  tensor(0.0224, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "91000 of 100000:  tensor(0.0223, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "91500 of 100000:  tensor(0.0223, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "92000 of 100000:  tensor(0.0224, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "92500 of 100000:  tensor(0.0223, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "93000 of 100000:  tensor(0.0218, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "93500 of 100000:  tensor(0.0223, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "94000 of 100000:  tensor(0.0216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "94500 of 100000:  tensor(0.0222, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "95000 of 100000:  tensor(0.0216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "95500 of 100000:  tensor(0.0220, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "96000 of 100000:  tensor(0.0220, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "96500 of 100000:  tensor(0.0218, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "97000 of 100000:  tensor(0.0218, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "97500 of 100000:  tensor(0.0217, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "98000 of 100000:  tensor(0.0217, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "98500 of 100000:  tensor(0.0216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "99000 of 100000:  tensor(0.0216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "99500 of 100000:  tensor(0.0216, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_tot = 0\n",
    "\n",
    "loops = 100000\n",
    "check_every = 500\n",
    "\n",
    "# training loop\n",
    "for i in range(loops):\n",
    "    log_idx = random.randint(1,4)\n",
    "#     log_idx = 4\n",
    "    batch_indices = torch.randint(0,input_contexts[log_idx].shape[0],(batch_size,))\n",
    "\n",
    "    batch = input_contexts[log_idx][batch_indices]\n",
    "\n",
    "    word_length = len(batch[0])\n",
    "\n",
    "    embeds = torch.transpose(all_char_embeds[batch],0,1)\n",
    "    \n",
    "    factors = torch.where(freqs > 0,1/(freqs+1e-18),0)\n",
    "    \n",
    "    factors[:-1] /= factors[:-1].mean()\n",
    "    \n",
    "    adjustment_factors = torch.transpose(factors[batch],0,1)\n",
    "    \n",
    "    adjustment_factors = adjustment_factors.view((word_length,batch_size,1))\n",
    "    \n",
    "    adjustment_factors[:-1] /= adjustment_factors[:-1].mean()\n",
    "#     print(adjustment_factors , embeds.shape)\n",
    "\n",
    "    states = [init_state] + [torch.zeros((batch_size,state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((batch_size,embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,batch_size,embed_size))\n",
    "\n",
    "    for j in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,j)\n",
    "\n",
    "    outputs[-1] = states[-1] @ w_so + b_o\n",
    "    \n",
    "    distances = (torch.cdist(outputs,all_char_embeds[:-1]) ** 2).sum(2,keepdim=True)#is actually distances squared\n",
    "        \n",
    "    filtered = torch.where(embeds != 1e10, ((outputs-embeds)**2 / distances), 0)\n",
    "    \n",
    "    ones = torch.where(embeds != 1e10, 1, 0)\n",
    "    \n",
    "    loss = (filtered*adjustment_factors).sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in network_params:\n",
    "        p.data -= 1e-3*p.grad\n",
    "        p.grad = None\n",
    "        \n",
    "    loss_tot+= loss/ adjustment_factors.sum()\n",
    "    if i % check_every==0 and i>0:\n",
    "        print(f\"{i} of {loops}: \" , loss_tot / (check_every))\n",
    "        loss_tot = 0\n",
    "#     print('o',outputs)\n",
    "#     print('e',embeds)\n",
    "#     print('wl',word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "17d8265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    word_length = len(word)\n",
    "\n",
    "    embeds = all_char_embeds[word]\n",
    "\n",
    "    states = [init_state]+[torch.zeros((state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,embed_size))\n",
    "\n",
    "    for i in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,i)\n",
    "\n",
    "    return states[-1] @ w_so + b_o\n",
    "\n",
    "\n",
    "def get_next(text):\n",
    "    word = [char_to_int[c] for c in text] +[0]\n",
    "\n",
    "    pred = predict(word)\n",
    "\n",
    "    pred = pred.view(1,embed_size)\n",
    "    dists = torch.cdist(pred,all_char_embeds[:-1])\n",
    "    dists = dists.view(-1)\n",
    "    dists = torch.exp(-7*dists)\n",
    "    dists/=dists.sum()\n",
    "    sampled = (torch.multinomial(dists,1)).item()\n",
    "    return int_to_char[sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3608a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chuvtyixa.\n",
      "puxai.\n",
      "dhyi.\n",
      "depey.\n",
      "fhyvih.\n",
      "wyyii.\n",
      "cosuthay.\n",
      "dhashay.\n",
      "khixiyyen.\n",
      "chuvriiq.\n",
      "pugyae.\n",
      "phkavbqpxasya.\n",
      "mhzawayi.\n",
      "polmi.\n",
      "fhistya.\n",
      "pudvhpya.\n",
      "puxnai.\n",
      "shetzi.\n",
      "whuvhian.\n",
      "mhqevici.\n",
      "chuvgyaxy.\n",
      "whtjmvvoie.\n",
      "cottukhlvi.\n",
      "gsitviy.\n",
      "drarviy.\n",
      "mafujey.\n",
      "fyaa.\n",
      "xtivey.\n",
      "dtikcya.\n",
      "mhmecana.\n",
      "sopodayikh.\n",
      "dya.\n",
      "phpozkeviy.\n",
      "catqateh.\n",
      "kuiy.\n",
      "warqin.\n",
      "peftia.\n",
      "pagfy.\n",
      "mhvixje.\n",
      "bhyka.\n",
      "quyhi.\n",
      "qtiaiy.\n",
      "dhinayn.\n",
      "xgavyi.\n",
      "whuqmyia.\n",
      "phjuvvqgjubnii.\n",
      "barsevuvn.\n",
      "bartioii.\n",
      "gpyyay.\n",
      "kuaa.\n",
      "qayvfya.\n",
      "phmwaga.\n",
      "kuyy.\n",
      "kuaa.\n",
      "whumlae.\n",
      "fhyxay.\n",
      "koqzia.\n",
      "bunhovehapeh.\n",
      "tttpdhiy.\n",
      "gcishiy.\n",
      "phlehin.\n",
      "cedtagya.\n",
      "kuannae.\n",
      "xehy.\n",
      "chyviniiy.\n",
      "luba.\n",
      "gdythan.\n",
      "luxa.\n",
      "cepriivmey.\n",
      "faxttan.\n",
      "dsacwih.\n",
      "khedeynwvxya.\n",
      "wurbyn.\n",
      "wrebci.\n",
      "gwypavetnhn.\n",
      "dsicvuia.\n",
      "grhoxiiie.\n",
      "khynh.\n",
      "doay.\n",
      "pyyn.\n",
      "whuqdi.\n",
      "cerpin.\n",
      "zeruy.\n",
      "wevuviuq.\n",
      "fuanny.\n",
      "wyya.\n",
      "phsjsqveraoy.\n",
      "chuqzyyya.\n",
      "qncwvy.\n",
      "chqyy.\n",
      "dhyy.\n",
      "musqii.\n",
      "batregivquii.\n",
      "ghewmay.\n",
      "basnyay.\n",
      "qyan.\n",
      "cejhycaa.\n",
      "zagay.\n",
      "jhadhova.\n",
      "gjahyhaiy.\n"
     ]
    }
   ],
   "source": [
    "start_st = ''\n",
    "\n",
    "for _ in range(100):\n",
    "    st = start_st\n",
    "    curr = 'a'\n",
    "    while curr!='.':\n",
    "        curr = get_next(st)\n",
    "        st+=curr\n",
    "    print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "088c8955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35.6892, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((all_char_embeds[char_to_int['y']]-all_char_embeds[char_to_int['j']])**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "16f2916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2277e+01,  3.9978e+00, -2.0790e+00, -6.4634e+00, -9.7122e-01,\n",
       "          9.1355e+00],\n",
       "        [ 6.2265e-02, -4.4034e-01, -6.3207e-02, -4.7214e-01,  9.0608e-01,\n",
       "          8.7690e-01],\n",
       "        [-7.4045e-01, -2.3842e-01,  1.1262e-01,  7.2173e-01, -3.0205e-01,\n",
       "         -8.4768e-01],\n",
       "        [-6.0282e-01, -1.2161e-01,  1.5330e-01,  5.2217e-01, -2.4655e-01,\n",
       "         -7.8859e-01],\n",
       "        [-7.0304e-01, -9.2246e-03,  3.6205e-01,  5.7091e-01, -2.2912e-01,\n",
       "         -9.5274e-01],\n",
       "        [ 1.0702e-01, -8.1980e-01, -1.4485e-01, -8.2107e-02,  1.1554e+00,\n",
       "          7.8707e-01],\n",
       "        [-7.8850e-01, -1.9774e-02, -7.0644e-03,  5.9431e-01, -2.7647e-01,\n",
       "         -9.7013e-01],\n",
       "        [-6.2197e-01,  1.8999e-01,  1.1287e-01,  4.8376e-01, -4.2226e-01,\n",
       "         -6.9665e-01],\n",
       "        [ 2.9039e-01, -5.6543e-01,  2.5713e-01,  5.0401e-02,  1.7475e-01,\n",
       "          4.8427e-01],\n",
       "        [ 6.7046e-01, -9.4411e-01, -4.5649e-01,  5.3217e-01,  1.4235e+00,\n",
       "          1.0210e+00],\n",
       "        [-1.0164e+00, -1.7325e-01,  2.4312e-01,  4.9226e-01,  6.0506e-03,\n",
       "         -8.1928e-01],\n",
       "        [-8.9562e-01,  1.0359e-01,  7.7052e-02,  4.3307e-01, -3.6444e-01,\n",
       "         -1.0758e+00],\n",
       "        [-7.1908e-01, -3.7401e-01, -2.5860e-01,  2.6823e-01, -4.2853e-01,\n",
       "         -4.5904e-01],\n",
       "        [-8.4248e-01, -2.6128e-01,  2.8181e-01,  7.6602e-01, -3.0453e-01,\n",
       "         -8.3622e-01],\n",
       "        [ 5.0055e-01,  5.5198e-01,  7.1911e-02,  2.6911e-01, -2.7371e-01,\n",
       "          7.2909e-02],\n",
       "        [-3.7897e-01, -6.9171e-01,  3.2174e-01,  3.0704e-01,  8.4066e-01,\n",
       "          7.9155e-01],\n",
       "        [-8.6112e-01, -1.5958e-01,  1.4435e-01,  6.9071e-01, -2.4806e-01,\n",
       "         -8.5104e-01],\n",
       "        [-1.0457e+00, -5.1417e-02,  4.9737e-02,  6.6096e-01, -4.3542e-01,\n",
       "         -9.2307e-01],\n",
       "        [-2.1121e-01, -3.7399e-02,  2.1950e-01,  2.3223e-01, -4.1148e-01,\n",
       "         -3.6981e-01],\n",
       "        [-3.3669e-01,  6.8572e-02,  9.0394e-02,  3.9533e-01, -3.3153e-01,\n",
       "         -6.0879e-01],\n",
       "        [-2.7502e-01, -7.7839e-02,  8.0429e-02,  3.5586e-01, -2.0466e-01,\n",
       "         -2.8948e-01],\n",
       "        [ 4.2199e-02, -4.6526e-01, -4.4285e-01,  4.9536e-01,  4.9825e-01,\n",
       "          5.0040e-01],\n",
       "        [-1.0480e+00, -1.5148e-01,  1.1588e-01,  6.7853e-01, -4.9221e-01,\n",
       "         -1.1125e+00],\n",
       "        [-8.5051e-01, -2.4062e-01,  1.3172e-01,  6.6420e-01, -1.1986e-01,\n",
       "         -8.7804e-01],\n",
       "        [-9.9286e-01, -5.0466e-02,  3.0969e-01,  6.0857e-01, -5.8328e-01,\n",
       "         -1.2374e+00],\n",
       "        [ 5.1352e-01, -9.7621e-02, -4.4222e-01, -1.3568e-01,  6.2766e-01,\n",
       "          4.0350e-01],\n",
       "        [-7.6733e-01,  6.6893e-02,  3.1561e-01,  7.2345e-01, -3.9452e-01,\n",
       "         -1.0686e+00],\n",
       "        [ 1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10,\n",
       "          1.0000e+10]], requires_grad=True)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_char_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea083d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
