{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf6862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in ./old/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./old/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, filelock, torch\n",
      "Successfully installed filelock-3.12.2 mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1 typing-extensions-4.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.40.0-cp311-cp311-macosx_10_9_universal2.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-macosx_11_0_arm64.whl (63 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.25.0-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./old/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./old/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./old/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.40.0 kiwisolver-1.4.4 matplotlib-3.7.2 numpy-1.25.0 pillow-10.0.0 pyparsing-3.0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c8043312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3ce67c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = open('names.txt','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0053f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "print(names_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8554a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "char_to_int['.'] = 0\n",
    "int_to_char[0] = '.'\n",
    "\n",
    "for char_num in range(ord('a'),ord('z')+1):\n",
    "    integer_representation = char_num-ord('a')+1\n",
    "    char_to_int[chr(char_num)] = integer_representation\n",
    "    int_to_char[integer_representation] = chr(char_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0853e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "embed_size = 6\n",
    "\n",
    "state_size = 20\n",
    "\n",
    "hidden_size = 100\n",
    "\n",
    "vocab_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "84d731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "char_vector_size = 2\n",
    "input_contexts , input_labels = [[] for _ in range(5)], [[] for _ in range(5)]\n",
    "\n",
    "for name in names_list:\n",
    "    log_padded_length = math.ceil(math.log(len(name))/math.log(2))\n",
    "    padded_length = int(2**log_padded_length)\n",
    "    context = [char_to_int[char] for char in name]  + [0] + [vocab_size-1]*(padded_length-len(name)) \n",
    "    input_contexts[log_padded_length].append(context)\n",
    "#   instead of using labels, we can compare the result to the character vectors to find a likely match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8d6bfff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1404, 0.1485, 0.0116, 0.0155, 0.0241, 0.0895, 0.0040, 0.0084, 0.0334,\n",
       "        0.0776, 0.0127, 0.0221, 0.0612, 0.0291, 0.0803, 0.0348, 0.0045, 0.0012,\n",
       "        0.0557, 0.0355, 0.0244, 0.0137, 0.0113, 0.0041, 0.0031, 0.0428, 0.0105,\n",
       "        0.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = [0 for i in range(vocab_size-1)]\n",
    "\n",
    "for log_len in range(1,5):\n",
    "    contexts = input_contexts[log_len]\n",
    "    for c in contexts:\n",
    "        for int_char in c:\n",
    "            if int_char<vocab_size-1:\n",
    "                freqs[int_char] += 1\n",
    "                \n",
    "freqs = torch.tensor(freqs+[0],dtype=torch.float64)\n",
    "freqs/=freqs.sum()\n",
    "\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e63c25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = input_contexts[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "40819a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "all_char_embeds = torch.randn((vocab_size,embed_size))\n",
    "\n",
    "all_char_embeds[vocab_size-1] = 10**10\n",
    "\n",
    "w_eh = torch.randn((embed_size, hidden_size)) * 0.5\n",
    "\n",
    "w_sh = torch.randn((state_size, hidden_size)) * 0.5\n",
    "w_so = torch.randn((state_size, embed_size)) *0.5\n",
    "\n",
    "w_hs = torch.randn((hidden_size, state_size)) *0.5\n",
    "\n",
    "b_h = torch.zeros((hidden_size,))\n",
    "b_s = torch.zeros((state_size,))\n",
    "b_o = torch.zeros((embed_size,))\n",
    "\n",
    "init_state = 2*torch.sigmoid(torch.randn((state_size,)))\n",
    "\n",
    "network_params = [init_state,w_eh,w_sh,w_so,w_hs,b_h,b_s,b_o,all_char_embeds]\n",
    "\n",
    "for p in network_params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "68feafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_and_embed(states , embeds, hiddens, outputs, idx):\n",
    "    hiddens[idx] = 2*torch.sigmoid((states[idx] @ w_sh) + (embeds[idx] @ w_eh) + b_h) -1\n",
    "    states[idx+1] = 2*torch.sigmoid(hiddens[idx] @ w_hs + b_s) - 1\n",
    "    outputs[idx] = states[idx] @ w_so + b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0ed9af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in range(len(input_contexts)):\n",
    "    input_contexts[i] = torch.tensor(input_contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fef2cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 of 100000:  tensor(0.0357, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "1000 of 100000:  tensor(0.0345, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "1500 of 100000:  tensor(0.0327, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "2000 of 100000:  tensor(0.0318, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "2500 of 100000:  tensor(0.0307, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "3000 of 100000:  tensor(0.0301, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "3500 of 100000:  tensor(0.0295, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "4000 of 100000:  tensor(0.0289, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "4500 of 100000:  tensor(0.0288, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "5000 of 100000:  tensor(0.0283, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "5500 of 100000:  tensor(0.0276, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "6000 of 100000:  tensor(0.0274, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "6500 of 100000:  tensor(0.0273, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "7000 of 100000:  tensor(0.0269, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "7500 of 100000:  tensor(0.0266, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "8000 of 100000:  tensor(0.0262, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "8500 of 100000:  tensor(0.0260, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "9000 of 100000:  tensor(0.0258, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "9500 of 100000:  tensor(0.0252, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "10000 of 100000:  tensor(0.0254, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "10500 of 100000:  tensor(0.0248, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "11000 of 100000:  tensor(0.0242, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "11500 of 100000:  tensor(0.0243, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "12000 of 100000:  tensor(0.0241, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "12500 of 100000:  tensor(0.0237, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "13000 of 100000:  tensor(0.0239, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "13500 of 100000:  tensor(0.0232, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "14000 of 100000:  tensor(0.0231, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "14500 of 100000:  tensor(0.0223, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "15000 of 100000:  tensor(0.0224, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "15500 of 100000:  tensor(0.0225, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "16000 of 100000:  tensor(0.0228, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "16500 of 100000:  tensor(0.0219, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "17000 of 100000:  tensor(0.0216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "17500 of 100000:  tensor(0.0214, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "18000 of 100000:  tensor(0.0210, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "18500 of 100000:  tensor(0.0216, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "19000 of 100000:  tensor(0.0210, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "19500 of 100000:  tensor(0.0205, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "20000 of 100000:  tensor(0.0204, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "20500 of 100000:  tensor(0.0206, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "21000 of 100000:  tensor(0.0205, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "21500 of 100000:  tensor(0.0201, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "22000 of 100000:  tensor(0.0198, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "22500 of 100000:  tensor(0.0203, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "23000 of 100000:  tensor(0.0197, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "23500 of 100000:  tensor(0.0196, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "24000 of 100000:  tensor(0.0195, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "24500 of 100000:  tensor(0.0194, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "25000 of 100000:  tensor(0.0192, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "25500 of 100000:  tensor(0.0189, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "26000 of 100000:  tensor(0.0187, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "26500 of 100000:  tensor(0.0190, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "27000 of 100000:  tensor(0.0191, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "27500 of 100000:  tensor(0.0186, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "28000 of 100000:  tensor(0.0183, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "28500 of 100000:  tensor(0.0186, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "29000 of 100000:  tensor(0.0183, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "29500 of 100000:  tensor(0.0183, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "30000 of 100000:  tensor(0.0184, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "30500 of 100000:  tensor(0.0180, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "31000 of 100000:  tensor(0.0179, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "31500 of 100000:  tensor(0.0180, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "32000 of 100000:  tensor(0.0177, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "32500 of 100000:  tensor(0.0180, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "33000 of 100000:  tensor(0.0174, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "33500 of 100000:  tensor(0.0177, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "34000 of 100000:  tensor(0.0172, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "34500 of 100000:  tensor(0.0180, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "35000 of 100000:  tensor(0.0178, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "35500 of 100000:  tensor(0.0176, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "36000 of 100000:  tensor(0.0175, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "36500 of 100000:  tensor(0.0175, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "37000 of 100000:  tensor(0.0174, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "37500 of 100000:  tensor(0.0173, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "38000 of 100000:  tensor(0.0170, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "38500 of 100000:  tensor(0.0173, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "39000 of 100000:  tensor(0.0171, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "39500 of 100000:  tensor(0.0169, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "40000 of 100000:  tensor(0.0172, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "40500 of 100000:  tensor(0.0167, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "41000 of 100000:  tensor(0.0168, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "41500 of 100000:  tensor(0.0169, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "42000 of 100000:  tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "42500 of 100000:  tensor(0.0170, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "43000 of 100000:  tensor(0.0168, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "43500 of 100000:  tensor(0.0164, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "44000 of 100000:  tensor(0.0167, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "44500 of 100000:  tensor(0.0164, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "45000 of 100000:  tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "45500 of 100000:  tensor(0.0165, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "46000 of 100000:  tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "46500 of 100000:  tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "47000 of 100000:  tensor(0.0164, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "47500 of 100000:  tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "48000 of 100000:  tensor(0.0162, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "48500 of 100000:  tensor(0.0164, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "49000 of 100000:  tensor(0.0163, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "49500 of 100000:  tensor(0.0162, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "50000 of 100000:  tensor(0.0163, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "50500 of 100000:  tensor(0.0167, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "51000 of 100000:  tensor(0.0163, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "51500 of 100000:  tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "52000 of 100000:  tensor(0.0164, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "52500 of 100000:  tensor(0.0167, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "53000 of 100000:  tensor(0.0164, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53500 of 100000:  tensor(0.0165, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "54000 of 100000:  tensor(0.0165, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "54500 of 100000:  tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "55000 of 100000:  tensor(0.0162, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "55500 of 100000:  tensor(0.0159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "56000 of 100000:  tensor(0.0158, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "56500 of 100000:  tensor(0.0160, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "57000 of 100000:  tensor(0.0161, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "57500 of 100000:  tensor(0.0162, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "58000 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "58500 of 100000:  tensor(0.0162, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "59000 of 100000:  tensor(0.0158, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "59500 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "60000 of 100000:  tensor(0.0160, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "60500 of 100000:  tensor(0.0159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "61000 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "61500 of 100000:  tensor(0.0160, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "62000 of 100000:  tensor(0.0159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "62500 of 100000:  tensor(0.0163, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "63000 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "63500 of 100000:  tensor(0.0160, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "64000 of 100000:  tensor(0.0163, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "64500 of 100000:  tensor(0.0162, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "65000 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "65500 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "66000 of 100000:  tensor(0.0158, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "66500 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "67000 of 100000:  tensor(0.0159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "67500 of 100000:  tensor(0.0158, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "68000 of 100000:  tensor(0.0161, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "68500 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "69000 of 100000:  tensor(0.0159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "69500 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "70000 of 100000:  tensor(0.0158, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "70500 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "71000 of 100000:  tensor(0.0158, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "71500 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "72000 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "72500 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "73000 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "73500 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "74000 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "74500 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "75000 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "75500 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "76000 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "76500 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "77000 of 100000:  tensor(0.0160, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "77500 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "78000 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "78500 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "79000 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "79500 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "80000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "80500 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "81000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "81500 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "82000 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "82500 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "83000 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "83500 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "84000 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "84500 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "85000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "85500 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "86000 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "86500 of 100000:  tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "87000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "87500 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "88000 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "88500 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "89000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "89500 of 100000:  tensor(0.0157, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "90000 of 100000:  tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "90500 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "91000 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "91500 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "92000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "92500 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "93000 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "93500 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "94000 of 100000:  tensor(0.0155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "94500 of 100000:  tensor(0.0150, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "95000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "95500 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "96000 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "96500 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "97000 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "97500 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "98000 of 100000:  tensor(0.0154, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "98500 of 100000:  tensor(0.0156, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "99000 of 100000:  tensor(0.0152, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "99500 of 100000:  tensor(0.0153, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_tot = 0\n",
    "\n",
    "loops = 100000\n",
    "check_every = 500\n",
    "\n",
    "# training loop\n",
    "for i in range(loops):\n",
    "    log_idx = random.randint(1,4)\n",
    "#     log_idx = 4\n",
    "    batch_indices = torch.randint(0,input_contexts[log_idx].shape[0],(batch_size,))\n",
    "\n",
    "    batch = input_contexts[log_idx][batch_indices]\n",
    "\n",
    "    word_length = len(batch[0])\n",
    "\n",
    "    embeds = torch.transpose(all_char_embeds[batch],0,1)\n",
    "    \n",
    "    factors = torch.where(freqs > 0,1/(freqs+1e-18),0)\n",
    "    \n",
    "    factors[:-1] /= factors[:-1].mean()\n",
    "    \n",
    "    adjustment_factors = torch.transpose(factors[batch],0,1)\n",
    "    \n",
    "    adjustment_factors = adjustment_factors.view((word_length,batch_size,1))\n",
    "    \n",
    "    adjustment_factors[:-1] /= adjustment_factors[:-1].mean()\n",
    "#     print(adjustment_factors , embeds.shape)\n",
    "\n",
    "    states = [init_state] + [torch.zeros((batch_size,state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((batch_size,embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,batch_size,embed_size))\n",
    "\n",
    "    for j in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,j)\n",
    "\n",
    "    outputs[-1] = states[-1] @ w_so + b_o\n",
    "    \n",
    "    distances = (torch.cdist(outputs,all_char_embeds[:-1]) ** 2).sum(2,keepdim=True)#is actually distances squared\n",
    "        \n",
    "    filtered = torch.where(embeds != 1e10, ((outputs-embeds)**2 / distances), 0)\n",
    "    \n",
    "    ones = torch.where(embeds != 1e10, 1, 0)\n",
    "    \n",
    "    loss = (filtered*adjustment_factors).sum()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in network_params:\n",
    "        p.data -= 3e-3*p.grad\n",
    "        p.grad = None\n",
    "        \n",
    "    loss_tot+= loss/ adjustment_factors.sum()\n",
    "    if i % check_every==0 and i>0:\n",
    "        print(f\"{i} of {loops}: \" , loss_tot / (check_every))\n",
    "        loss_tot = 0\n",
    "#     print('o',outputs)\n",
    "#     print('e',embeds)\n",
    "#     print('wl',word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "17d8265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    word_length = len(word)\n",
    "\n",
    "    embeds = all_char_embeds[word]\n",
    "\n",
    "    states = [init_state]+[torch.zeros((state_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    hiddens = [torch.zeros((embed_size,)) for _ in range(word_length-1)]\n",
    "\n",
    "    outputs = torch.zeros((word_length,embed_size))\n",
    "\n",
    "    for i in range(word_length-1):\n",
    "        process_state_and_embed(states,embeds ,hiddens,outputs,i)\n",
    "\n",
    "    return states[-1] @ w_so + b_o\n",
    "\n",
    "\n",
    "def get_next(text):\n",
    "    word = [char_to_int[c] for c in text] +[0]\n",
    "\n",
    "    pred = predict(word)\n",
    "\n",
    "    pred = pred.view(1,embed_size)\n",
    "    dists = torch.cdist(pred,all_char_embeds[:-1])\n",
    "    dists = dists.view(-1)\n",
    "    dists = torch.exp(-5*dists)\n",
    "    dists/=dists.sum()\n",
    "    sampled = (torch.multinomial(dists,1)).item()\n",
    "    return int_to_char[sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3608a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacvulaewe.\n",
      "jaccutheludurut.\n",
      "jacxafa.\n",
      "jacvut.\n",
      "jacs.\n",
      "jack.\n",
      "jacmeleutenti.\n",
      "jaczacahuher.\n",
      "jacguytu.\n",
      "jacguubavotetuuwo.\n",
      "jacve.\n",
      "jacbatueshnt.\n",
      "jacpazuweeuces.\n",
      "jacku.\n",
      "jacpazutuutaua.\n",
      "jacfutuerene.\n",
      "jacfut.\n",
      "jackuunuqhh.\n",
      "jacku.\n",
      "jacxecoderus.\n",
      "jackuulaqequ.\n",
      "jacbuus.\n",
      "jacfu.\n",
      "jacqu.\n",
      "jacvaswovoleeates.\n",
      "jaczaca.\n",
      "jaczaca.\n",
      "jacq.\n",
      "jacpoweh.\n",
      "jaczagheaubut.\n",
      "jacfat.\n",
      "jacmewosaajep.\n",
      "jaczuteugutugtruxere.\n",
      "jacb.\n",
      "jacbuus.\n",
      "jaczunto.\n",
      "jacguucopu.\n",
      "jacvadtetub.\n",
      "jacvulaewe.\n",
      "jacfuleetea.\n",
      "jacxopereenhuwizofut.\n",
      "jacguafe.\n",
      "jacmewetorepetnat.\n",
      "jacfu.\n",
      "jacquuwes.\n",
      "jack.\n",
      "jackuuti.\n",
      "jacxaxhe.\n",
      "jacvor.\n",
      "jacfuraetosurlh.\n",
      "jacv.\n",
      "jaczacelu.\n",
      "jacguaxuteunuutowebenfucothe.\n",
      "jacguuzebuw.\n",
      "jacfutuenaturorae.\n",
      "jackuutiuteteutetuturuc.\n",
      "jacpaz.\n",
      "jaccaw.\n",
      "jacku.\n",
      "jaczuteupera.\n",
      "jaccar.\n",
      "jacfulaotore.\n",
      "jaczafa.\n",
      "jacxesherrojireubua.\n",
      "jacfadhodisa.\n",
      "jacguuzevose.\n",
      "jacxes.\n",
      "jacbuytu.\n",
      "jacvot.\n",
      "jacguujek.\n",
      "jacpet.\n",
      "jacvadna.\n",
      "jacf.\n",
      "jacpazulae.\n",
      "jacbu.\n",
      "jaccat.\n",
      "jacputu.\n",
      "jacb.\n",
      "jacmos.\n",
      "jacguupejelaeleeri.\n",
      "jacfh.\n",
      "jacfulaesemola.\n",
      "jacbuus.\n",
      "jacxeba.\n",
      "jacfutueleteadewe.\n",
      "jaccal.\n",
      "jacbuulusureulaowire.\n",
      "jacfuruaten.\n",
      "jacbu.\n",
      "jaczulaixura.\n",
      "jackuutewet.\n",
      "jacpavu.\n",
      "jacsunre.\n",
      "jacpaslatu.\n",
      "jacxes.\n",
      "jacxaxuh.\n",
      "jaczacautensoci.\n",
      "jacfutuagere.\n",
      "jacfuleeleen.\n",
      "jacfutuerint.\n"
     ]
    }
   ],
   "source": [
    "start_st = 'jac'\n",
    "\n",
    "for _ in range(100):\n",
    "    st = start_st\n",
    "    curr = 'a'\n",
    "    while curr!='.':\n",
    "        curr = get_next(st)\n",
    "        st+=curr\n",
    "    print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "088c8955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9190e-05, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((all_char_embeds[char_to_int['a']]-all_char_embeds[char_to_int['e']])**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "16f2916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1277e+00, -8.8232e-02, -1.0335e+00,  2.5983e+00, -8.8906e-01,\n",
       "         -3.1492e-01],\n",
       "        [ 2.2695e+00, -6.4594e-03, -2.1022e+00,  2.8194e+00, -1.0321e+00,\n",
       "         -1.0548e+00],\n",
       "        [-1.7191e+00, -4.8078e-01,  9.0666e-01, -1.0642e+00,  6.0315e-01,\n",
       "          5.1761e-01],\n",
       "        [-1.3007e+00, -2.9655e-01,  9.0441e-01, -9.7577e-01,  4.4994e-01,\n",
       "          8.3598e-01],\n",
       "        [-1.0109e+00, -2.5439e-01,  4.1026e-01, -1.2056e-02,  1.1623e-01,\n",
       "          1.1777e-01],\n",
       "        [ 2.7456e+00, -5.0969e-01, -1.8866e+00,  4.1694e+00, -1.5524e+00,\n",
       "         -8.5540e-01],\n",
       "        [-1.8919e+00, -1.2437e-01,  1.0180e+00, -1.5503e+00,  7.2874e-01,\n",
       "          9.2309e-01],\n",
       "        [-1.4867e+00, -3.3611e-01,  1.0614e+00, -7.1992e-01,  8.0783e-01,\n",
       "          7.6978e-01],\n",
       "        [ 1.4528e+00, -6.7225e-01, -1.2368e+00,  2.5108e+00, -2.3421e-01,\n",
       "         -1.0520e+00],\n",
       "        [ 3.5377e+00, -8.7898e-01, -1.8128e+00,  4.1241e+00, -1.3459e+00,\n",
       "         -1.4490e-01],\n",
       "        [-1.3747e+00, -3.9754e-01,  6.6348e-01, -1.2749e+00,  5.2850e-01,\n",
       "          3.1225e-01],\n",
       "        [-1.8629e+00, -4.1757e-01,  1.2122e+00, -1.7152e+00,  8.7825e-01,\n",
       "          8.4523e-01],\n",
       "        [-9.3991e-01, -1.9005e-01, -2.2965e-01,  3.6837e-02, -1.6290e-01,\n",
       "         -7.5531e-02],\n",
       "        [-1.4444e+00, -1.7017e-01,  1.0065e+00, -1.3046e+00,  2.7247e-01,\n",
       "          9.4670e-01],\n",
       "        [-1.1528e+00,  1.0338e-01,  1.3999e-01,  4.2098e-01,  2.8970e-01,\n",
       "          2.9338e-01],\n",
       "        [ 3.3479e+00,  9.8869e-02, -1.7914e+00,  3.4595e+00, -1.5905e+00,\n",
       "         -1.0733e+00],\n",
       "        [-1.5592e+00, -2.8662e-01,  9.3643e-01, -1.0771e+00,  3.4835e-01,\n",
       "          6.7050e-01],\n",
       "        [-2.0994e+00, -4.2329e-01,  1.2291e+00, -1.7626e+00,  9.7790e-01,\n",
       "          8.5087e-01],\n",
       "        [-9.3212e-01, -3.7066e-01,  1.9063e-01,  3.4785e-01, -3.5264e-01,\n",
       "          4.4865e-01],\n",
       "        [-1.3493e+00, -1.2104e-01,  6.8786e-01, -4.6056e-01,  3.6456e-01,\n",
       "          4.6707e-01],\n",
       "        [-5.7122e-01, -2.6525e-01,  5.5073e-02,  3.2920e-01,  2.0541e-01,\n",
       "          4.0036e-01],\n",
       "        [ 1.7745e+00, -8.7210e-02, -1.0402e+00,  2.6205e+00, -1.0806e+00,\n",
       "         -5.9993e-01],\n",
       "        [-1.7495e+00, -6.3803e-01,  8.9337e-01, -1.2289e+00,  3.2310e-01,\n",
       "          7.6885e-01],\n",
       "        [-7.4089e-01, -4.6686e-01,  3.9610e-01, -1.1060e-01,  1.3548e-01,\n",
       "          3.2361e-01],\n",
       "        [-2.1532e+00, -1.9363e-01,  1.2968e+00, -1.3973e+00,  6.0923e-01,\n",
       "          9.1739e-01],\n",
       "        [ 5.6471e-01, -1.0438e-02, -1.3987e+00,  3.4390e+00, -1.2992e+00,\n",
       "         -1.0889e+00],\n",
       "        [-1.6500e+00, -3.4834e-01,  1.0581e+00, -9.1716e-01,  4.2416e-01,\n",
       "          7.4905e-01],\n",
       "        [ 1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10,\n",
       "          1.0000e+10]], requires_grad=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_char_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea083d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
